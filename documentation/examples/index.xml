<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Build Prototypes on Qdrant - Vector Database</title><link>https://qdrant.tech/documentation/examples/</link><description>Recent content in Build Prototypes on Qdrant - Vector Database</description><generator>Hugo</generator><language>en-us</language><managingEditor>info@qdrant.tech (Andrey Vasnetsov)</managingEditor><webMaster>info@qdrant.tech (Andrey Vasnetsov)</webMaster><atom:link href="https://qdrant.tech/documentation/examples/index.xml" rel="self" type="application/rss+xml"/><item><title>GraphRAG with Qdrant and Neo4j</title><link>https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><author>info@qdrant.tech (Andrey Vasnetsov)</author><guid>https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/</guid><description>&lt;h1 id="build-a-graphrag-agent-with-neo4j-and-qdrant">Build a GraphRAG Agent with Neo4j and Qdrant&lt;/h1>
&lt;p>&lt;img src="https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/image0.png" alt="image0">&lt;/p>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>Time: 30 min&lt;/th>
 &lt;th>Level: Intermediate&lt;/th>
 &lt;th>Output: &lt;a href="https://github.com/qdrant/examples/blob/master/graphrag_neo4j/graphrag.py" target="_blank" rel="noopener nofollow">GitHub&lt;/a>&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;/tbody>
&lt;/table>
&lt;p>To make Artificial Intelligence (AI) systems more intelligent and reliable, we face a paradox: Large Language Models (LLMs) possess remarkable reasoning capabilities, yet they struggle to connect information in ways humans find intuitive. While groundbreaking, Retrieval-Augmented Generation (RAG) approaches often fall short when tasked with complex information synthesis. When asked to connect disparate pieces of information or understand holistic concepts across large documents, these systems frequently miss crucial connections that would be obvious to human experts.&lt;/p></description></item><item><title>Multitenancy with LlamaIndex</title><link>https://qdrant.tech/documentation/examples/llama-index-multitenancy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><author>info@qdrant.tech (Andrey Vasnetsov)</author><guid>https://qdrant.tech/documentation/examples/llama-index-multitenancy/</guid><description>&lt;h1 id="multitenancy-with-llamaindex">Multitenancy with LlamaIndex&lt;/h1>
&lt;p>If you are building a service that serves vectors for many independent users, and you want to isolate their
data, the best practice is to use a single collection with payload-based partitioning. This approach is
called &lt;strong>multitenancy&lt;/strong>. Our guide on the &lt;a href="https://qdrant.tech/documentation/guides/multiple-partitions/">Separate Partitions&lt;/a> describes
how to set it up in general, but if you use &lt;a href="https://qdrant.tech/documentation/integrations/llama-index/">LlamaIndex&lt;/a> as a
backend, you may prefer reading a more specific instruction. So here it is!&lt;/p></description></item><item><title>Private Chatbot for Interactive Learning</title><link>https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><author>info@qdrant.tech (Andrey Vasnetsov)</author><guid>https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/</guid><description>&lt;h1 id="private-chatbot-for-interactive-learning">Private Chatbot for Interactive Learning&lt;/h1>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>Time: 120 min&lt;/th>
 &lt;th>Level: Advanced&lt;/th>
 &lt;th>&lt;/th>
 &lt;th>&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;/tbody>
&lt;/table>
&lt;p>With chatbots, companies can scale their training programs to accommodate a large workforce, delivering consistent and standardized learning experiences across departments, locations, and time zones. Furthermore, having already completed their online training, corporate employees might want to refer back old course materials. Most of this information is proprietary to the company, and manually searching through an entire library of materials takes time. However, a chatbot built on this knowledge can respond in the blink of an eye.&lt;/p></description></item><item><title>Implement Cohere RAG connector</title><link>https://qdrant.tech/documentation/examples/cohere-rag-connector/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><author>info@qdrant.tech (Andrey Vasnetsov)</author><guid>https://qdrant.tech/documentation/examples/cohere-rag-connector/</guid><description>&lt;h1 id="implement-custom-connector-for-cohere-rag">Implement custom connector for Cohere RAG&lt;/h1>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>Time: 45 min&lt;/th>
 &lt;th>Level: Intermediate&lt;/th>
 &lt;th>&lt;/th>
 &lt;th>&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;/tbody>
&lt;/table>
&lt;p>The usual approach to implementing Retrieval Augmented Generation requires users to build their prompts with the
relevant context the LLM may rely on, and manually sending them to the model. Cohere is quite unique here, as their
models can now speak to the external tools and extract meaningful data on their own. You can virtually connect any data
source and let the Cohere LLM know how to access it. Obviously, vector search goes well with LLMs, and enabling semantic
search over your data is a typical case.&lt;/p></description></item><item><title>Question-Answering System for AI Customer Support</title><link>https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><author>info@qdrant.tech (Andrey Vasnetsov)</author><guid>https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/</guid><description>&lt;h1 id="question-answering-system-for-ai-customer-support">Question-Answering System for AI Customer Support&lt;/h1>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>Time: 120 min&lt;/th>
 &lt;th>Level: Advanced&lt;/th>
 &lt;th>&lt;/th>
 &lt;th>&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;/tbody>
&lt;/table>
&lt;p>Maintaining top-notch customer service is vital to business success. As your operation expands, so does the influx of customer queries. Many of these queries are repetitive, making automation a time-saving solution.
Your support team&amp;rsquo;s expertise is typically kept private, but you can still use AI to automate responses securely.&lt;/p>
&lt;p>In this tutorial we will setup a private AI service that answers customer support queries with high accuracy and effectiveness. By leveraging Cohere&amp;rsquo;s powerful models (deployed to &lt;a href="https://cohere.com/deployment-options/aws" target="_blank" rel="noopener nofollow">AWS&lt;/a>) with Qdrant Hybrid Cloud, you can create a fully private customer support system. Data synchronization, facilitated by &lt;a href="https://airbyte.com/" target="_blank" rel="noopener nofollow">Airbyte&lt;/a>, will complete the setup.&lt;/p></description></item><item><title>Chat With Product PDF Manuals Using Hybrid Search</title><link>https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><author>info@qdrant.tech (Andrey Vasnetsov)</author><guid>https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/</guid><description>&lt;h1 id="chat-with-product-pdf-manuals-using-hybrid-search">Chat With Product PDF Manuals Using Hybrid Search&lt;/h1>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>Time: 120 min&lt;/th>
 &lt;th>Level: Advanced&lt;/th>
 &lt;th>Output: &lt;a href="https://github.com/infoslack/qdrant-example/blob/main/HC-demo/HC-DO-LlamaIndex-Jina-v2.ipynb" target="_blank" rel="noopener nofollow">GitHub&lt;/a>&lt;/th>
 &lt;th>&lt;a href="https://githubtocolab.com/infoslack/qdrant-example/blob/main/HC-demo/HC-DO-LlamaIndex-Jina-v2.ipynb" target="_blank" rel="noopener nofollow">&lt;img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab">&lt;/a>&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;/tbody>
&lt;/table>
&lt;p>With the proliferation of digital manuals and the increasing demand for quick and accurate customer support, having a chatbot capable of efficiently parsing through complex PDF documents and delivering precise information can be a game-changer for any business.&lt;/p>
&lt;p>In this tutorial, we&amp;rsquo;ll walk you through the process of building a RAG-based chatbot, designed specifically to assist users with understanding the operation of various household appliances.
We&amp;rsquo;ll cover the essential steps required to build your system, including data ingestion, natural language understanding, and response generation for customer support use cases.&lt;/p></description></item><item><title>Region-Specific Contract Management System</title><link>https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><author>info@qdrant.tech (Andrey Vasnetsov)</author><guid>https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/</guid><description>&lt;h1 id="region-specific-contract-management-system">Region-Specific Contract Management System&lt;/h1>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>Time: 90 min&lt;/th>
 &lt;th>Level: Advanced&lt;/th>
 &lt;th>&lt;/th>
 &lt;th>&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;/tbody>
&lt;/table>
&lt;p>Contract management benefits greatly from Retrieval Augmented Generation (RAG), streamlining the handling of lengthy business contract texts. With AI assistance, complex questions can be asked and well-informed answers generated, facilitating efficient document management. This proves invaluable for businesses with extensive relationships, like shipping companies, construction firms, and consulting practices. Access to such contracts is often restricted to authorized team members due to security and regulatory requirements, such as GDPR in Europe, necessitating secure storage practices.&lt;/p></description></item><item><title>RAG System for Employee Onboarding</title><link>https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><author>info@qdrant.tech (Andrey Vasnetsov)</author><guid>https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/</guid><description>&lt;h1 id="rag-system-for-employee-onboarding">RAG System for Employee Onboarding&lt;/h1>
&lt;p>Public websites are a great way to share information with a wide audience. However, finding the right information can be
challenging, if you are not familiar with the website&amp;rsquo;s structure or the terminology used. That&amp;rsquo;s what the search bar is
for, but it is not always easy to formulate a query that will return the desired results, if you are not yet familiar
with the content. This is even more important in a corporate environment, and for the new employees, who are just
starting to learn the ropes, and don&amp;rsquo;t even know how to ask the right questions yet. You may have even the best intranet
pages, but onboarding is more than just reading the documentation, it is about understanding the processes. Semantic
search can help with finding right resources easier, but wouldn&amp;rsquo;t it be easier to just chat with the website, like you
would with a colleague?&lt;/p></description></item><item><title>Private RAG Information Extraction Engine</title><link>https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><author>info@qdrant.tech (Andrey Vasnetsov)</author><guid>https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/</guid><description>&lt;h1 id="private-rag-information-extraction-engine">Private RAG Information Extraction Engine&lt;/h1>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>Time: 90 min&lt;/th>
 &lt;th>Level: Advanced&lt;/th>
 &lt;th>&lt;/th>
 &lt;th>&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;/tbody>
&lt;/table>
&lt;p>Handling private documents is a common task in many industries. Various businesses possess a large amount of
unstructured data stored as huge files that must be processed and analyzed. Industry reports, financial analysis, legal
documents, and many other documents are stored in PDF, Word, and other formats. Conversational chatbots built on top of
RAG pipelines are one of the viable solutions for finding the relevant answers in such documents. However, if we want to
extract structured information from these documents, and pass them to downstream systems, we need to use a different
approach.&lt;/p></description></item><item><title>Movie Recommendation System</title><link>https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><author>info@qdrant.tech (Andrey Vasnetsov)</author><guid>https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/</guid><description>&lt;h1 id="movie-recommendation-system">Movie Recommendation System&lt;/h1>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>Time: 120 min&lt;/th>
 &lt;th>Level: Advanced&lt;/th>
 &lt;th>Output: &lt;a href="https://github.com/infoslack/qdrant-example/blob/main/HC-demo/HC-OVH.ipynb" target="_blank" rel="noopener nofollow">GitHub&lt;/a>&lt;/th>
 &lt;th>&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;/tbody>
&lt;/table>
&lt;p>In this tutorial, you will build a mechanism that recommends movies based on defined preferences. Vector databases like Qdrant are good for storing high-dimensional data, such as user and item embeddings. They can enable personalized recommendations by quickly retrieving similar entries based on advanced indexing techniques. In this specific case, we will use &lt;a href="https://qdrant.tech/articles/sparse-vectors/">sparse vectors&lt;/a> to create an efficient and accurate recommendation system.&lt;/p></description></item><item><title>Blog-Reading Chatbot with GPT-4o</title><link>https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><author>info@qdrant.tech (Andrey Vasnetsov)</author><guid>https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/</guid><description>&lt;h1 id="blog-reading-chatbot-with-gpt-4o">Blog-Reading Chatbot with GPT-4o&lt;/h1>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>Time: 90 min&lt;/th>
 &lt;th>Level: Advanced&lt;/th>
 &lt;th>&lt;a href="https://github.com/qdrant/examples/blob/langchain-lcel-rag/langchain-lcel-rag/Langchain-LCEL-RAG-Demo.ipynb" target="_blank" rel="noopener nofollow">GitHub&lt;/a>&lt;/th>
 &lt;th>&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;/tbody>
&lt;/table>
&lt;p>In this tutorial, you will build a RAG system that combines blog content ingestion with the capabilities of semantic search. &lt;strong>OpenAI&amp;rsquo;s GPT-4o LLM&lt;/strong> is powerful, but scaling its use requires us to supply context systematically.&lt;/p>
&lt;p>RAG enhances the LLM&amp;rsquo;s generation of answers by retrieving relevant documents to aid the question-answering process. This setup showcases the integration of advanced search and AI language processing to improve information retrieval and generation tasks.&lt;/p></description></item></channel></rss>